{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624f38a6-d4b2-4dc0-a56d-d1c2c642535d",
   "metadata": {},
   "source": [
    "# Collection of further information\n",
    "\n",
    "This notebook performs a domain analysis based on the data `real_domains.csv`. First, it checks the correctness of the specified `A records` and `MX records`. The current A-records and MX-records of the top-level domain are determined. In the next step, the `redirects` and `HTTP status codes` are obtained from the top-level domains. The Python package called `dnspython` is used for the determination. In addition, a further analysis of the MX records determines their locations and the corresponding ASNs. Free IP geolocation databases from MaxMind are used for this.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, the required installations and imports are made, the session is initialized and the basis data is collected from the Postgres database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6289df2-604f-4041-9b85-bf72f438b74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n",
      "Collecting dnspython\n",
      "  Downloading dnspython-2.1.0-py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: dnspython\n",
      "Successfully installed dnspython-2.1.0\n",
      "Collecting geoip2\n",
      "  Downloading geoip2-4.2.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.6.2\n",
      "  Downloading aiohttp-3.7.4.post0-cp39-cp39-manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting maxminddb<3.0.0,>=2.0.0\n",
      "  Downloading maxminddb-2.0.3.tar.gz (286 kB)\n",
      "\u001b[K     |████████████████████████████████| 286 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.9/site-packages (from geoip2) (2.25.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.2 in /opt/conda/lib/python3.9/site-packages (from geoip2) (1.26.6)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (4.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (21.2.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp39-cp39-manylinux2014_x86_64.whl (315 kB)\n",
      "\u001b[K     |████████████████████████████████| 315 kB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2) (3.10.0.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp39-cp39-manylinux2014_x86_64.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 12.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->geoip2) (2021.5.30)\n",
      "Building wheels for collected packages: maxminddb\n",
      "  Building wheel for maxminddb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for maxminddb: filename=maxminddb-2.0.3-py2.py3-none-any.whl size=15284 sha256=32e308f76a82d0efe4fc1acfb1a44f9fcc89998636f8987e22ed290df990466c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ad/0c/82/79e41ebe67044c68a5087459a9ea7447cb0756019071318197\n",
      "Successfully built maxminddb\n",
      "Installing collected packages: multidict, yarl, async-timeout, maxminddb, aiohttp, geoip2\n",
      "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 geoip2-4.2.0 maxminddb-2.0.3 multidict-5.1.0 yarl-1.6.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/05 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/07/05 17:39:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/07/05 17:39:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Required installations\n",
    "!pip install ipynb\n",
    "!pip install dnspython\n",
    "!pip install geoip2\n",
    "\n",
    "# Required imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from ipynb.fs.full.Functions import *\n",
    "\n",
    "# PostgreSQL access data\n",
    "host = \"bda_gr4_database\"\n",
    "port = \"5432\"\n",
    "database = \"domainanalysis\"\n",
    "user = \"postgres\"\n",
    "password = \"postgres\"\n",
    "\n",
    "# PostgreSQL connection url\n",
    "connection = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"domain_analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read data from the database\n",
    "domains_df = spark.read \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", connection) \\\n",
    "                .option(\"dbtable\", \"domain\") \\\n",
    "                .option(\"user\", user) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .load()\n",
    "\n",
    "# Display the data frame\n",
    "#domains_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e96ed-e7d7-44e0-9a4c-2b3bae564f68",
   "metadata": {},
   "source": [
    "## 1. Validation of A and MX records\n",
    "\n",
    "In the following chapter, the functions are imported from the notebook `Functions.ipynb` in order to use them for the definition of the `UDFs`. In doing so, the current `a-records` and `mx-records` are to be determined from the `top-level-domain`.  If the records cannot be determined, the returned errors are stored in separate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3714087f-28cf-499c-9a21-cf9c9fbd1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "args = domains_df.select(\"top_level_domain\").toPandas().values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f30dd-f163-4391-85ea-06b8bbb6e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_map_a_record = execute_threaded_fn(getARecords, args)\n",
    "result_map_a_record_error = execute_threaded_fn(getARecords_error, args)\n",
    "result_map_mx_record = execute_threaded_fn(getMXRecords, args)\n",
    "result_map_mx_record_error = execute_threaded_fn(getMXRecords_error, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1093216-0fd7-4ae1-a0c3-a187344a87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getARecords_udf(top_level_domain):\n",
    "    return result_map_a_record[top_level_domain]\n",
    "\n",
    "def getARecords_error_udf(top_level_domain):\n",
    "    return result_map_a_record_error[top_level_domain]\n",
    "\n",
    "def getMXRecords_udf(top_level_domain):\n",
    "    return result_map_mx_record[top_level_domain]\n",
    "\n",
    "def getMXRecords_error_udf(top_level_domain):\n",
    "    return result_map_mx_record_error[top_level_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8977420-ff1b-4f23-8fc4-39211203e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating of UDF's\n",
    "udf_getARecords = udf(getARecords_udf, ArrayType(StringType()))\n",
    "udf_getARecords_error = udf(getARecords_error_udf,  IntegerType())\n",
    "\n",
    "udf_getMXRecords = udf(getMXRecords_udf, ArrayType(StringType()))\n",
    "udf_getMXRecords_error = udf(getMXRecords_error_udf,  IntegerType())\n",
    "\n",
    "udf_remove_last_char_in_array = udf(fn_remove_dot, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fb87f-9904-45f4-8887-bdeb1d69d662",
   "metadata": {},
   "source": [
    "Next, the A and MX records are checked by calling the UDFs and creating the returned results in new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc074022-afb0-4293-9e14-03a4ea7249da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns with the results\n",
    "domains_checked_df = domains_df.withColumn(\"a_record_checked\", udf_getARecords(\"top_level_domain\")) \\\n",
    "                            .withColumn(\"a_record_checked_error\", udf_getARecords_error(\"top_level_domain\")) \\\n",
    "                            .withColumn(\"mx_record_checked\", udf_getMXRecords(\"top_level_domain\")) \\\n",
    "                            .withColumn(\"mx_record_checked\", udf_remove_last_char_in_array(col(\"mx_record_checked\"))) \\\n",
    "                            .withColumn(\"mx_record_checked_error\", udf_getMXRecords_error(\"top_level_domain\"))\n",
    "domains_checked_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86919685-ab99-4b42-8065-e7f3211b0b35",
   "metadata": {},
   "source": [
    "In preparation for writing to the database, the data frame is put into the correct order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcae96a-9f79-4588-86be-3693320b8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the order of the data frame\n",
    "domains_checked_df = domains_checked_df.select(\"top_level_domain\", \"a_record\", \"a_record_checked\", \"a_record_checked_error\", \"mx_record\", \"mx_record_checked\", \"mx_record_checked_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d19651-857d-4e01-b100-965418716252",
   "metadata": {},
   "source": [
    "Last but not least, let's check if the records have either not been changed, changed completely or partially in comparison to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83143f17-45b2-47bd-a0c5-82937641fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of checked A-records\n",
    "a_record_checked_count = domains_checked_df.withColumn('a_record_checked', explode(col('a_record_checked'))) \\\n",
    "        .groupBy('a_record_checked') \\\n",
    "        .count()\n",
    "\n",
    "# Count the occurrence of checked MX-records\n",
    "mx_record_checked_count = domains_checked_df.withColumn('mx_record_checked', explode(col('mx_record_checked'))) \\\n",
    "        .groupBy('mx_record_checked') \\\n",
    "        .count()\n",
    "\n",
    "# Finally, create new data frames only containing the top 10 A-/MX-records\n",
    "a_record_count_top_ten_df = a_record_checked_count.orderBy(['count'], ascending = [False]).limit(10)\n",
    "mx_record_count_top_ten_df = mx_record_checked_count.orderBy(['count'], ascending = [False]).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd369bd-2215-4521-b4f3-55534c250fa9",
   "metadata": {},
   "source": [
    "Finally, the columns `a_record` and `mx_record` are removed from the `domains_checked_df` data frame. Furthermore, the first 15 rows of the data frame are displayed as a check for writing to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20bf19-d35c-407f-8d71-bbb7818d1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns and show the data frame\n",
    "domains_checked_df = domains_checked_df.drop(\"a_record\").drop(\"mx_record\")\n",
    "domains_checked_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4f9e4-a6d3-4ac7-82b0-a4e22ea6c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data frame\n",
    "a_record_count_top_ten_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56227837-4fc9-4b0a-b2f4-978c29782d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data frame\n",
    "mx_record_count_top_ten_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536d2be-19d2-40e6-ac3e-ff6c4c138296",
   "metadata": {},
   "source": [
    "After the generated data frames have been checked, they must be written to the PostgreSQL database for data visualisation. To enable a faster write speed, `repartition` and `batchsize` are specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00c012-7ae2-43de-8194-5d38d474d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data frames to the PostgreSQL database\n",
    "a_record_count_top_ten_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"a_record_checked_count_global\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "mx_record_count_top_ten_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"mx_record_checked_count_global\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "domains_checked_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"domain_records_checked\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f96af-9be4-45df-a0f4-5fe10cdae227",
   "metadata": {},
   "source": [
    "## 2. Determination of redirects and HTTP status codes\n",
    "\n",
    "This chapter contains the definition of the `redirects` and `HTTP status` codes to the top level domains. In the following, the functions are imported from the function notebook `Functions.ipynb` in order to use them for the definition of the `UDFs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db5e36-8cf0-4de2-8526-6f496f0e7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_map_redirect = execute_threaded_fn(getRedirectUrl, args)\n",
    "result_map_statuscode = execute_threaded_fn(getStatusCodeUrl, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79cff4-fe4f-4aa6-8e41-9a71d0699e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRedirectUrl_udf(top_level_domain):\n",
    "    return result_map_redirect[top_level_domain]\n",
    "\n",
    "def getStatusCodeUrl_udf(top_level_domain):\n",
    "    return result_map_statuscode[top_level_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155f430-3b6b-4991-9a70-32e3930f1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating of UDF's\n",
    "udf_getRedirectUrl = udf(getRedirectUrl_udf, StringType())\n",
    "udf_getStatusCodeUrl = udf(getStatusCodeUrl_udf, IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794f7fb-8359-408b-86df-c6acc81c2df4",
   "metadata": {},
   "source": [
    "In this block, the `redirections` and the `HTTP status codes` are determined by calling the UDF functions. For this purpose, the column `top_level_domain` is passed as a parameter. Subsequently, the redirections and status codes are stored in new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e15e74-32b1-4a1f-9d68-d5a68e92cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns with the results\n",
    "domains_redirect_df = domains_df.withColumn(\"redirection\", udf_getRedirectUrl(\"top_level_domain\")) \\\n",
    "                                .withColumn(\"status_code\", udf_getStatusCodeUrl(\"top_level_domain\"))\n",
    "domains_redirect_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443747b0-e267-412b-9e57-def5d2ee12aa",
   "metadata": {},
   "source": [
    "For storage in the PostgreSQL database, the `a_record` and `mx_record` columns are removed from the `domains_redirect_df` data frame and the first 15 rows of the data frame are displayed for checking for writing to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750fe84-993f-4706-9671-850ead9941d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns and show the data frame\n",
    "domains_redirect_df = domains_redirect_df.drop(\"a_record\").drop(\"mx_record\")\n",
    "domains_redirect_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc47be-3563-4de2-a152-191d067fb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_redirect_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"domain_redirection\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9d889-f1ed-40ae-b6fe-c7ce7ad70ee2",
   "metadata": {},
   "source": [
    "## 3. MX record location and ASN determination\n",
    "\n",
    "In this section, the `locations` and `providers` are identified based on the ANS using the MX records already checked. For each MX record the iso code, location, postal code, latitude, longitude and the organisation of the autonomous system are presented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359fc9ec-7879-460b-8b75-2983200295cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the database\n",
    "domain_records_checked_df = spark.read \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", connection) \\\n",
    "                .option(\"dbtable\", \"domain_records_checked\") \\\n",
    "                .option(\"user\", user) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .load()\n",
    "\n",
    "# Drop columns\n",
    "domain_records_checked_df = domain_records_checked_df.drop(\"a_record_checked\").drop(\"a_record_checked_error\").drop(\"mx_record_checked_error\")\n",
    "\n",
    "# Display the data frame\n",
    "domain_records_checked_df.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62db54e-98cd-4a88-bd32-544ec1eefe7b",
   "metadata": {},
   "source": [
    "Next, the functions from the function notebook `Functions.ipynb` that are to be used for the definition of the `UDFs` are imported. After that, StructTypes of StructFields are created to define the return types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d8eec-adfb-4994-bd90-9b96dad33aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_location = StructType([\n",
    "    StructField(\"iso_code\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"postal\", StringType(), True),\n",
    "    StructField(\"latitude\", StringType(), True),\n",
    "    StructField(\"longitude\", StringType(), True)])\n",
    "\n",
    "schema_asn = StructType([\n",
    "    StructField(\"autonomous_system_organization\", StringType(), True)])\n",
    "\n",
    "udf_getGeoLite2_Location = udf(getGeoLite2_Location, schema_location)\n",
    "udf_getGeoLite2_ASN = udf(getGeoLite2_ASN, schema_asn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05088e93-67c7-4808-af29-ae165f95907f",
   "metadata": {},
   "source": [
    "In order to be able to perform the location and provider query, the ip address of the mx records must first be found out. Based on this, the `locations` and the `providers` are determined and the data frame `domains_mx_record_geolite2_df` is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcfbbd-673a-4d99-9edf-dcc3e80f4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns with the results\n",
    "domains_mx_record_geolite2_df = domain_records_checked_df.select(domain_records_checked_df.top_level_domain,explode(domain_records_checked_df.mx_record_checked).alias('mx_record_checked'))\n",
    "domains_mx_record_geolite2_df = domains_mx_record_geolite2_df.withColumn(\"mx_record_ip\", udf_getARecords(\"mx_record_checked\")) \\\n",
    "                            .withColumn('mx_record_ip', explode(col('mx_record_ip'))) \\\n",
    "                            .withColumn(\"location\", udf_getGeoLite2_Location(\"mx_record_ip\")) \\\n",
    "                            .withColumn(\"asn\", udf_getGeoLite2_ASN(\"mx_record_ip\")) \\\n",
    "                            .select(\"top_level_domain\", \"mx_record_checked\", \"mx_record_ip\", \"location.*\", \"asn.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44719c-95bd-403e-a606-2d36052c70db",
   "metadata": {},
   "source": [
    "For storage in the PostgreSQL database, the first 15 rows of the data frame are displayed for checking for writing to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5722f-fcfb-4f22-a1a5-40b2b00c6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data frame\n",
    "domains_mx_record_geolite2_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d630a-0e0c-4f77-8064-d4810857e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data frame to the PostgreSQL database\n",
    "domains_mx_record_geolite2_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"domain_mx_record_geolite2\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e1bbb-a7b0-454a-9843-440119f71be0",
   "metadata": {},
   "source": [
    "## 4. IPv6 and SOA information fetch\n",
    "\n",
    "This section contains the fetch of IPv6, nameserver information and a ranking of the top ten master nameservers and the companies behind.\n",
    "The following block generates the required functions as user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0da8be-434f-46bb-ab4d-84c331f3df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_map_aaaa = execute_threaded_fn(IPv6Record, args)\n",
    "result_map_aaaa_error = execute_threaded_fn(IPv6Record_error, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e449f-a522-45f9-85d3-b5f1d45b6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAAAA_record_udf(top_level_domain):\n",
    "    return result_map_aaaa[top_level_domain]\n",
    "\n",
    "def getAAAA_record_error_udf(top_level_domain):\n",
    "    return result_map_aaaa_error[top_level_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09db57-8d10-4626-b43f-0307bf12f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_IPv6Record = udf(getAAAA_record_udf, BooleanType())\n",
    "udf_IPv6Record_error = udf(getAAAA_record_error_udf, IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa67aa-8f10-4e7e-aff2-c3125f3f2ca8",
   "metadata": {},
   "source": [
    "### IPv6 information\n",
    "The IPv6 information provided by the following code are the availability of IPv6 (`ipv6_available`, boolean) and the possible error code during a request (`ipv6_error`). Therefore, the dataframe 'domains_ipv6_df' is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1947081-0ffd-421e-90c0-3ffdd8da90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for ipv6 data\n",
    "domains_ipv6_df = domains_df.withColumn(\"ipv6_available\", udf_IPv6Record('top_level_domain'))\\\n",
    "                        .withColumn(\"ipv6_error\", udf_IPv6Record_error(\"top_level_domain\"))\\\n",
    "                        .drop('mx_record').drop('a_record')\n",
    "\n",
    "domains_ipv6_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756ea79-6c37-4bf1-8316-6bd18d5d9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the data frame to the PostgreSQL database\n",
    "domains_ipv6_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"ip_v6_information\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781c555-87ea-4b75-8149-f151d7a34bf5",
   "metadata": {},
   "source": [
    "### SOA information\n",
    "Among the SOA record, the names of the nameservers `nameservers` (iincluding master server) are fetched in the following. The variable `nameservers_error` indicates if problems ocurred during the request wheres as `nameservers_count` contains the number of nameservers used per domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45340ffd-4a90-489a-bc35-35a3712ed90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_map_soa_information = execute_threaded_fn(getSOAInformation, args)\n",
    "result_map_soa_information_error = execute_threaded_fn(getSOAInformation_error, args)\n",
    "result_map_nameservers = execute_threaded_fn(getNameServers, args)\n",
    "result_map_nameservers_error = execute_threaded_fn(getNameServers_error, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dfe441-e8fa-4f22-8c87-06c26111ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSOAInformation_udf(top_level_domain):\n",
    "    return result_map_soa_information[top_level_domain]\n",
    "\n",
    "def getSOAInformation_error_udf(top_level_domain):\n",
    "    return result_map_soa_information_error[top_level_domain]\n",
    "\n",
    "def getNameServers_udf(top_level_domain):\n",
    "    return result_map_nameservers[top_level_domain]\n",
    "\n",
    "def getNameServers_error_udf(top_level_domain):\n",
    "    return result_map_nameservers_error[top_level_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619ac45-9e8b-40d6-92d8-b9366c8d9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_getSOAInformation = udf(getSOAInformation_udf, ArrayType(StringType()))\n",
    "udf_getSOAInformation_error = udf(getSOAInformation_error_udf, IntegerType())\n",
    "udf_getNameServers = udf(getNameServers_udf, ArrayType(StringType()))\n",
    "udf_getNameServers_error = udf(getNameServers_error_udf, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffc3d3-da61-4843-b822-d4e8216b3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for SOA data and drop unnecessary columns\n",
    "domains_soa_df = domains_df.withColumn(\"soa_information\", udf_getSOAInformation(\"top_level_domain\"))\\\n",
    "                        .withColumn(\"soa_information_error\", udf_getSOAInformation_error(\"top_level_domain\"))\\\n",
    "                        .withColumn(\"nameservers\", udf_getNameServers(\"top_level_domain\"))\\\n",
    "                        .withColumn(\"nameservers_error\", udf_getNameServers_error(\"top_level_domain\"))\\\n",
    "                        .drop('mx_record').drop('a_record')\n",
    "\n",
    "# Add nameserver count variable\n",
    "def count_arr(arr): return 0 if arr == None else len(arr)\n",
    "count_arr_udf = udf(count_arr, IntegerType())\n",
    "domains_soa_df = domains_soa_df.withColumn(\"nameservers_count\", count_arr_udf('nameservers'))\n",
    "domains_soa_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a305bac-d297-49a4-93a1-f14e12c9def1",
   "metadata": {},
   "source": [
    "The details concerning the master nameserver are provided as ArrayType. As this is inconvenient with regard to the data structure (atomicity), the column `soa_infos_rep` is converted into a string type to separate its contents into separate variables.\n",
    "These are the name of the primary master nameserver `soa_name`, the refresh time of the SOA record executed by the secondary nameservers (`refresh`), the 'Time to live' (TTL), which defines how long a secondary nameserver caches the requested SOA information `minimum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c7617-e191-4b4a-bae8-76ff9c86dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change ArrayType<String> into String as preparation for information separation\n",
    "domains_soa_df = domains_soa_df.withColumn(\"soa_infos_rep\", concat_ws(\" \", \"soa_information\"))\n",
    "\n",
    "# Split SOA information into separate columns (all String)\n",
    "split_col = split(domains_soa_df['soa_infos_rep'], ' ')\n",
    "domains_soa_df = domains_soa_df.withColumn('soa_name', split_col.getItem(0))\\\n",
    "                        .withColumn('refresh', split_col.getItem(3))\\\n",
    "                        .withColumn('minimum', split_col.getItem(6))\n",
    "\n",
    "# Helping function to catch empty entries concerning the master nameserver\n",
    "def replace_empty_strings(x):\n",
    "    return when(col(x) == \"\", None).otherwise(col(x))\n",
    "\n",
    "domains_soa_df = domains_soa_df.withColumn(\"soa_name\", replace_empty_strings(\"soa_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11b91e-03ec-4e3f-a0d3-e0d9835ed7f2",
   "metadata": {},
   "source": [
    "Some fetched entries contain unnecessary characters which need to be removed (dot at the end of the name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaeff60-61cf-4a80-a192-2e0925e2dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last dot per soa mname\n",
    "domains_soa_df = domains_soa_df.withColumn('soa_name', regexp_replace('soa_name', '.$', ''))   \n",
    "\n",
    "# Remove last dot per nameserver entry\n",
    "lambda_dot_remove = lambda arr: [x[:-1] for x in arr]\n",
    "def fn_remove_dot(arr): return None if arr == None else lambda_dot_remove(arr)\n",
    "udf_remove_last_char_in_array = udf(fn_remove_dot, ArrayType(StringType()))\n",
    "\n",
    "domains_soa_df = domains_soa_df \\\n",
    "    .select(\"*\") \\\n",
    "    .withColumn('nameservers', udf_remove_last_char_in_array(col('nameservers')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221798f-1655-475a-8d7d-9c9ce30b122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type of the time setting columns into int\n",
    "domains_soa_df = domains_soa_df.withColumn(\"refresh\", domains_soa_df[\"refresh\"].cast(IntegerType()))\\\n",
    "                        .withColumn(\"minimum\", domains_soa_df[\"minimum\"].cast(IntegerType()))\\\n",
    "                        .drop('soa_information').drop('soa_infos_rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ee32a-db7d-4e03-9316-989a5c93f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the data frame to the PostgreSQL database\n",
    "domains_soa_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"soa\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857da4e9-aeac-4216-bc0d-a485a9846742",
   "metadata": {},
   "source": [
    "### Top ten master namservers and related company information\n",
    "This section creates a dataframe concerning the top ten master neameservers and the companies behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e47799-5e2f-4456-89a9-6175096359c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occrence of SOA records\n",
    "soa_name_count_top_ten_df = domains_soa_df.withColumn('soa_name', (col('soa_name'))) \\\n",
    "        .groupBy('soa_name') \\\n",
    "        .count()\n",
    "\n",
    "soa_name_count_top_ten_df = soa_name_count_top_ten_df.orderBy(['count'], ascending = [False]).limit(10)\n",
    "soa_name_count_top_ten_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998618a5-833e-49fe-ac2d-d5e95ce4b80b",
   "metadata": {},
   "source": [
    "The company informations per master nameserver will be added by a request of its IP adresses `ipv4`. The IP address(es) are the used within the functions concerning GeoLite2 to get the company information ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286d83b-e4a7-4b32-a040-22c205354263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove None entries (copmany information not available)\n",
    "soa_name_count_top_ten_df = soa_name_count_top_ten_df.na.drop(subset=[\"soa_name\"])\n",
    "\n",
    "soa_name_count_top_ten_df = soa_name_count_top_ten_df.withColumn(\"ipv4\", udf_getARecords(\"soa_name\"))\\\n",
    "                      .withColumn('ipv4', explode(col('ipv4'))) \\\n",
    "                      .withColumn(\"location\", udf_getGeoLite2_Location(\"ipv4\")) \\\n",
    "                      .withColumn(\"asn\", udf_getGeoLite2_ASN(\"ipv4\")) \\\n",
    "                      .select(\"soa_name\", \"count\", \"ipv4\", \"location.*\", \"asn.*\")\n",
    "#soa_name_count_top_ten_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c10d2-0bca-4b84-94e9-64929dedf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the data frame to the PostgreSQL database\n",
    "soa_name_count_top_ten_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"soa_top_ten\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0188245-c2b1-4751-a04e-0922ef389e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
