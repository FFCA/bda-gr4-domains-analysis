{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2ba390-9338-485e-a86f-17c149cd4b34",
   "metadata": {},
   "source": [
    "# 1. Implementation of an ETL process\n",
    "\n",
    "This notebook runs an ETL script on the base data, which extracts, transforms and finally loads the data into the PostgreSQL database.\n",
    "\n",
    "## Extraction\n",
    "\n",
    "First, the necessary imports are carried out, the database access data defined, the session initialised and the data fetched from the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c676f-8fc6-4e08-b566-31a507587ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# PostgreSQL access data\n",
    "host = \"bda_gr4_database\"\n",
    "port = \"5432\"\n",
    "database = \"domainanalysis\"\n",
    "user = \"postgres\"\n",
    "password = \"postgres\"\n",
    "table = \"domain\"\n",
    "\n",
    "# PostgreSQL connection url\n",
    "connection = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"etl_domains\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read csv file into Spark data frame\n",
    "domains_df = spark.read.csv('../data/real_domains.csv', escape = \"\\\"\").toDF(\"top_level_domain\", \"mx_record\", \"a_record\", \"timestamp\")\n",
    "\n",
    "# Delete the timestamp column\n",
    "domains_df = domains_df.drop('timestamp')\n",
    "\n",
    "# Display the data frame\n",
    "domains_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fb020-16cf-4781-bc2c-7a8943989fe5",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "The second step is the transformation of the data frame. The data set is passed to a function that cleans the data frame of special characters. Finally, empty lines are replaced by `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9fd7b-0a19-42ed-ad06-e722fa73482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean up a data frame\n",
    "def clean_data(df, column, to_delete, to_replace):\n",
    "    cleaned_df = df.withColumn(column, regexp_replace(column, to_delete, to_replace))\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2559f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the column names\n",
    "col_names = domains_df.schema.names\n",
    "\n",
    "# Clean up each column\n",
    "for column in col_names:\n",
    "    domains_df = clean_data(domains_df, column, '\\\\[|\\\\]|\\\\\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 rows\n",
    "domains_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956ee0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace all empty rows with \"None\" and split A- and MX-records\n",
    "domains_df = domains_df \\\n",
    "                .withColumn('mx_record', when(domains_df['mx_record'] == '', None).otherwise(split(domains_df['mx_record'], ','))) \\\n",
    "                .withColumn('a_record', when(domains_df['a_record'] == '', None).otherwise(split(domains_df['a_record'], ','))) \n",
    "\n",
    "# Display the data frame\n",
    "domains_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc1a97-3318-4b50-97f5-1e7e173bb37c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading\n",
    "\n",
    "The last step is to load the cleaned data frame into the PostgreSQL database. To speed up the writing process, `8 partitions` are created for parallel processing and the `batchsize` is set to `10000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae4ec0-73ae-4d05-8247-a4ae4e02da09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the data frame to the PostgreSQL database\n",
    "domains_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", table) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
