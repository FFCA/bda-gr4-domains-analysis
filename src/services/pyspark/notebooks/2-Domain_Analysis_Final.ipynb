{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624f38a6-d4b2-4dc0-a56d-d1c2c642535d",
   "metadata": {},
   "source": [
    "# Domain analysis\n",
    "\n",
    "This notebook performs a domain analysis based on the data `real_domains.csv`. First, it checks the correctness of the specified `A records` and `MX records`. The current A-records and MX-records of the top-level domain are determined. In the next step, the `redirects` and `HTTP status codes` are obtained from the top-level domains. The Python package called `dnspython` is used for the determination. In addition, a further analysis of the MX records determines their locations and the corresponding ASNs. Free IP geolocation databases from MaxMind are used for this.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, the required installations and imports are made, the session is initialized and the basis data is collected from the Postgres database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6289df2-604f-4041-9b85-bf72f438b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required installations\n",
    "!pip install ipynb\n",
    "!pip install dnspython\n",
    "!pip install geoip2\n",
    "\n",
    "# Required imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# PostgreSQL access data\n",
    "host = \"bda_gr4_database\"\n",
    "port = \"5432\"\n",
    "database = \"domainanalysis\"\n",
    "user = \"postgres\"\n",
    "password = \"postgres\"\n",
    "\n",
    "# PostgreSQL connection url\n",
    "connection = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"domain_analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read data from the database\n",
    "domains_df = spark.read \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", connection) \\\n",
    "                .option(\"dbtable\", \"domain\") \\\n",
    "                .option(\"user\", user) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .load()\n",
    "\n",
    "# Display the data frame\n",
    "domains_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e96ed-e7d7-44e0-9a4c-2b3bae564f68",
   "metadata": {},
   "source": [
    "## 1. Validation of A and MX records\n",
    "\n",
    "In the following chapter, the functions are imported from the notebook `Functions.ipynb` in order to use them for the definition of the `UDFs`. In doing so, the current `a-records` and `mx-records` are to be determined from the `top-level-domain`.  If the records cannot be determined, the returned errors are stored in separate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8977420-ff1b-4f23-8fc4-39211203e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all functions from Funtions.ipynb\n",
    "from ipynb.fs.full.Functions import getARecords, getARecords_error, getMXRecords, getMXRecords_error\n",
    "\n",
    "# Creating of UDF's\n",
    "udf_getARecords = udf(getARecords, ArrayType(StringType()))\n",
    "udf_getARecords_error = udf(getARecords_error, IntegerType())\n",
    "udf_getMXRecords = udf(getMXRecords, ArrayType(StringType()))\n",
    "udf_getMXRecords_error = udf(getMXRecords_error, IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fb87f-9904-45f4-8887-bdeb1d69d662",
   "metadata": {},
   "source": [
    "Next, the A and MX records are checked by calling the UDFs and creating the returned results in new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc074022-afb0-4293-9e14-03a4ea7249da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns with the results\n",
    "domains_checked_df = domains_df.withColumn(\"a_record_checked\", udf_getARecords(\"top_level_domain\")) \\\n",
    "                            .withColumn(\"a_record_checked_error\", udf_getARecords_error(\"top_level_domain\")) \\\n",
    "                            .withColumn(\"mx_record_checked\", udf_getMXRecords(\"top_level_domain\")) \\\n",
    "                            .withColumn(\"mx_record_checked_error\", udf_getMXRecords_error(\"top_level_domain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86919685-ab99-4b42-8065-e7f3211b0b35",
   "metadata": {},
   "source": [
    "In preparation for writing to the database, the data frame is put into the correct order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcae96a-9f79-4588-86be-3693320b8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the order of the data frame\n",
    "domains_checked_df = domains_checked_df.select(\"top_level_domain\", \"a_record\", \"a_record_checked\", \"a_record_checked_error\", \"mx_record\", \"mx_record_checked\", \"mx_record_checked_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d19651-857d-4e01-b100-965418716252",
   "metadata": {},
   "source": [
    "Last but not least, let's check if the records have either not been changed, changed completely or partially in comparison to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83143f17-45b2-47bd-a0c5-82937641fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occrence of checked A-records\n",
    "a_record_checked_count = domains_df.withColumn('a_record_checked', explode(col('a_record'))) \\\n",
    "        .groupBy('a_record_checked') \\\n",
    "        .count()\n",
    "\n",
    "# Count the occrence of checked MX-records\n",
    "mx_record_checked_count = domains_df.withColumn('mx_record_checked', explode(col('mx_record'))) \\\n",
    "        .groupBy('mx_record_checked') \\\n",
    "        .count()\n",
    "\n",
    "# Finally, create new data frames only containing the top 10 A-/MX-records\n",
    "a_record_count_top_ten_df = a_record_checked_count.orderBy(['count'], ascending = [False]).limit(10)\n",
    "mx_record_count_top_ten_df = mx_record_checked_count.orderBy(['count'], ascending = [False]).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd369bd-2215-4521-b4f3-55534c250fa9",
   "metadata": {},
   "source": [
    "Finally, the columns `a_record` and `mx_record` are removed from the `domains_checked_df` data frame. Furthermore, the first 15 rows of the data frame are displayed as a check for writing to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20bf19-d35c-407f-8d71-bbb7818d1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns and show the data frame\n",
    "domains_checked_df = domains_checked_df.drop(\"a_record\").drop(\"mx_record\")\n",
    "domains_checked_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4f9e4-a6d3-4ac7-82b0-a4e22ea6c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data frame\n",
    "a_record_count_top_ten_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56227837-4fc9-4b0a-b2f4-978c29782d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data frame\n",
    "mx_record_count_top_ten_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536d2be-19d2-40e6-ac3e-ff6c4c138296",
   "metadata": {},
   "source": [
    "After the generated data frames have been checked, they must be written to the PostgreSQL database for data visualisation. To enable a faster write speed, `repartition` and `batchsize` are specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00c012-7ae2-43de-8194-5d38d474d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data frames to the PostgreSQL database\n",
    "a_record_count_top_ten_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"a_record_checked_count_global\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "mx_record_count_top_ten_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"mx_record_checked_count_global\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n",
    "domains_checked_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"domain_records_checked\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f96af-9be4-45df-a0f4-5fe10cdae227",
   "metadata": {},
   "source": [
    "## 2. Determination of redirects and HTTP status codes\n",
    "\n",
    "This chapter contains the definition of the `redirects` and `HTTP status` codes to the top level domains. In the following, the functions are imported from the function notebook `Functions.ipynb` in order to use them for the definition of the `UDFs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155f430-3b6b-4991-9a70-32e3930f1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from Funtions.ipynb\n",
    "from ipynb.fs.full.Functions import *\n",
    "\n",
    "# Creating of UDF's\n",
    "udf_getRedirectUrl = udf(getRedirectUrl, StringType())\n",
    "udf_getStatusCodeUrl = udf(getStatusCodeUrl, IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794f7fb-8359-408b-86df-c6acc81c2df4",
   "metadata": {},
   "source": [
    "In this block, the `redirections` and the `HTTP status codes` are determined by calling the UDF functions. For this purpose, the column `top_level_domain` is passed as a parameter. Subsequently, the redirections and status codes are stored in new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e15e74-32b1-4a1f-9d68-d5a68e92cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns with the results\n",
    "domains_redirect_df = domains_df.withColumn(\"redirection\", udf_getRedirectUrl(\"top_level_domain\")) \\\n",
    "                                .withColumn(\"status_code\", udf_getStatusCodeUrl(\"top_level_domain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443747b0-e267-412b-9e57-def5d2ee12aa",
   "metadata": {},
   "source": [
    "For storage in the PostgreSQL database, the `a_record` and `mx_record` columns are removed from the `domains_redirect_df` data frame and the first 15 rows of the data frame are displayed for checking for writing to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750fe84-993f-4706-9671-850ead9941d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns and show the data frame\n",
    "domains_redirect_df = domains_redirect_df.drop(\"a_record\").drop(\"mx_record\")\n",
    "domains_redirect_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc47be-3563-4de2-a152-191d067fb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_redirect_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"domain_redirection\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9d889-f1ed-40ae-b6fe-c7ce7ad70ee2",
   "metadata": {},
   "source": [
    "## 3. MX record location and ASN determination\n",
    "\n",
    "In this section, the `locations` and `providers` are identified based on the ANS using the MX records already checked. For each MX record the iso code, location, postal code, latitude, longitude and the organisation of the autonomous system are presented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359fc9ec-7879-460b-8b75-2983200295cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the database\n",
    "domain_records_checked_df = spark.read \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", connection) \\\n",
    "                .option(\"dbtable\", \"domain_records_checked\") \\\n",
    "                .option(\"user\", user) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .load()\n",
    "\n",
    "# Drop columns\n",
    "domain_records_checked_df = domain_records_checked_df.drop(\"a_record_checked\").drop(\"a_record_checked_error\").drop(\"mx_record_checked_error\")\n",
    "\n",
    "# Display the data frame\n",
    "domain_records_checked_df.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62db54e-98cd-4a88-bd32-544ec1eefe7b",
   "metadata": {},
   "source": [
    "Next, the functions from the function notebook `Functions.ipynb` that are to be used for the definition of the `UDFs` are imported. After that, StructTypes of StructFields are created to define the return types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d8eec-adfb-4994-bd90-9b96dad33aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all functions from Funtions.ipynb\n",
    "from ipynb.fs.full.Functions import *\n",
    "\n",
    "schema_location = StructType([\n",
    "    StructField(\"iso_code\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"postal\", StringType(), True),\n",
    "    StructField(\"latitude\", StringType(), True),\n",
    "    StructField(\"longitude\", StringType(), True)])\n",
    "\n",
    "schema_asn = StructType([\n",
    "    StructField(\"autonomous_system_organization\", StringType(), True)])\n",
    "\n",
    "udf_getARecords = udf(getARecords, ArrayType(StringType()))\n",
    "udf_getGeoLite2_Location = udf(getGeoLite2_Location, schema_location)\n",
    "udf_getGeoLite2_ASN = udf(getGeoLite2_ASN, schema_asn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05088e93-67c7-4808-af29-ae165f95907f",
   "metadata": {},
   "source": [
    "In order to be able to perform the location and provider query, the ip address of the mx records must first be found out. Based on this, the `locations` and the `providers` are determined and the data frame `domains_mx_record_geolite2_df` is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcfbbd-673a-4d99-9edf-dcc3e80f4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new columns with the results\n",
    "domains_mx_record_geolite2_df = domain_records_checked_df.select(domain_records_checked_df.top_level_domain,explode(domain_records_checked_df.mx_record_checked).alias('mx_record_checked'))\n",
    "domains_mx_record_geolite2_df = domains_mx_record_geolite2_df.withColumn(\"mx_record_ip\", udf_getARecords(\"mx_record_checked\")) \\\n",
    "                            .withColumn('mx_record_ip', explode(col('mx_record_ip'))) \\\n",
    "                            .withColumn(\"location\", udf_getGeoLite2_Location(\"mx_record_ip\")) \\\n",
    "                            .withColumn(\"asn\", udf_getGeoLite2_ASN(\"mx_record_ip\")) \\\n",
    "                            .select(\"top_level_domain\", \"mx_record_checked\", \"mx_record_ip\", \"location.*\", \"asn.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44719c-95bd-403e-a606-2d36052c70db",
   "metadata": {},
   "source": [
    "For storage in the PostgreSQL database, the first 15 rows of the data frame are displayed for checking for writing to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5722f-fcfb-4f22-a1a5-40b2b00c6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data frame\n",
    "domains_mx_record_geolite2_df.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d630a-0e0c-4f77-8064-d4810857e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data frame to the PostgreSQL database\n",
    "domains_mx_record_geolite2_df.repartition(8).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", connection) \\\n",
    "    .option(\"dbtable\", \"domain_mx_record_geolite2\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"batchsize\", 10000) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
